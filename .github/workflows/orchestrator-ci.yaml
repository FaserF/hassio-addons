name: Orchestrator CI

on:
  push:
    branches:
      - master
  pull_request:
    branches:
      - master

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  # --------------------------------------------------------------------------------
  # CI START: Post initial comment
  # --------------------------------------------------------------------------------
  ci_start:
    name: üöÄ CI Start Notification
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
    steps:
      - name: üìù Post CI Starting Comment
        uses: actions/github-script@v7
        with:
          script: |
            const { data: comments } = await github.rest.issues.listComments({
               owner: context.repo.owner,
               repo: context.repo.repo,
               issue_number: context.issue.number,
            });

            const signature = "<!-- ci-start-comment -->";
            const existingComment = comments.find(c => c.user.type === 'Bot' && c.body.includes(signature));

            // If the comment already exists, skip posting a new one
            if (existingComment) {
                console.log("CI start comment already exists, skipping...");
                return;
            }

            let body = signature + "\n";
            body += "## üîÑ CI Tests Running\n\n";
            body += "Comprehensive CI tests are now running. This may take a few minutes.\n\n";
            body += "A detailed feedback comment will be posted once all checks are complete.\n\n";
            body += "---\n\n";
            body += "**üìã Merge Policy:**\n";
            body += "- PRs are typically only merged when **all CI tests pass**\n";
            body += "- If tests fail, you will receive automated guidance on how to fix the issues\n";
            body += "- PRs with failing tests may receive limited maintainer attention until resolved\n\n";
            body += "_*Workflow configuration errors are handled by maintainers_";

            await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
            });

  # --------------------------------------------------------------------------------
  # FILTER: Detect which add-ons have changed
  # --------------------------------------------------------------------------------
  generate-config:
    name: Generate Config
    runs-on: ubuntu-latest
    outputs:
      filters: ${{ steps.generator.outputs.filters }}
    steps:
      - name: ‚§µÔ∏è Check out code
        uses: actions/checkout@v4

      - name: üêç Generate Dynamic Filters
        id: generator
        run: |
          import os
          import json
          import uuid

          filters = {}
          # Scan for config.yaml to identify add-ons
          for root, dirs, files in os.walk("."):
              if "config.yaml" in files:
                  addon_name = os.path.relpath(root, ".")
                  if addon_name == ".": continue

                  # Standardize path separators
                  addon_name = addon_name.replace(os.path.sep, "/")

                  # Skip hidden directories EXCEPT .unsupported
                  # If the path starts with . and is NOT .unsupported, skip
                  # If the path is inside a hidden dir (like .git/foo), skip
                  parts = addon_name.split("/")
                  if parts[0].startswith(".") and parts[0] != ".unsupported":
                      continue
                  if len(parts) > 1 and any(p.startswith(".") and p != ".unsupported" for p in parts):
                       # This handles .unsupported/addon (allowed) but skips .git/addon or addon/.hidden
                       continue

                  filters[addon_name] = [f"{addon_name}/**"]

          # Dump as JSON (valid YAML)
          json_content = json.dumps(filters)

          delimiter = str(uuid.uuid4())
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"filters<<{delimiter}\n")
              f.write(json_content)
              f.write(f"\n{delimiter}\n")

        shell: python

  # --------------------------------------------------------------------------------
  # FILTER: Detect which add-ons have changed
  # --------------------------------------------------------------------------------
  filter:
    name: üîç Detect Changes
    needs: generate-config
    runs-on: ubuntu-latest
    outputs:
      addons: ${{ steps.filter.outputs.changes }}
      docs_only: ${{ steps.change-type.outputs.docs_only }}
      needs_build: ${{ steps.change-type.outputs.needs_build }}
    steps:
      - name: ‚§µÔ∏è Check out code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: üìÇ Run Paths Filter
        id: filter
        uses: dorny/paths-filter@v3
        with:
          filters: ${{ needs.generate-config.outputs.filters }}

      - name: üîé Analyze Change Types
        id: change-type
        run: |
          # Get all changed files in this push/PR
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            CHANGED_FILES=$(git diff --name-only "${{ github.event.pull_request.base.sha }}" "${{ github.sha }}" 2>/dev/null || git diff --name-only HEAD~1 2>/dev/null || git ls-tree -r HEAD --name-only)
          else
            CHANGED_FILES=$(git diff --name-only HEAD~1 2>/dev/null || git ls-tree -r HEAD --name-only)
          fi

          echo "Changed files:"
          echo "$CHANGED_FILES"

          # Categorize changes
          docs_only="true"
          needs_build="false"

          for file in $CHANGED_FILES; do
            # Check if file requires build (Dockerfile, config, scripts, etc.)
            if [[ "$file" == */Dockerfile ]] || \
               [[ "$file" == */build.yaml ]] || \
               [[ "$file" == */build.json ]] || \
               [[ "$file" == */config.yaml ]] || \
               [[ "$file" == */config.json ]] || \
               [[ "$file" == *run.sh ]] || \
               [[ "$file" == *.py ]] || \
               [[ "$file" == */rootfs/* ]] || \
               [[ "$file" == */root/* ]]; then
              needs_build="true"
              docs_only="false"
            # Check if it's NOT a documentation/workflow file
            elif [[ "$file" != *.md ]] && \
                 [[ "$file" != *.MD ]] && \
                 [[ "$file" != .github/workflows/* ]] && \
                 [[ "$file" != .github/*.md ]] && \
                 [[ "$file" != LICENSE* ]] && \
                 [[ "$file" != */CHANGELOG* ]] && \
                 [[ "$file" != .gitignore ]] && \
                 [[ "$file" != .editorconfig ]]; then
              docs_only="false"
            fi
          done

          echo "docs_only=$docs_only" >> "$GITHUB_OUTPUT"
          echo "needs_build=$needs_build" >> "$GITHUB_OUTPUT"
          echo "Results: docs_only=$docs_only, needs_build=$needs_build"

  # --------------------------------------------------------------------------------
  # LINT: Static Analysis (Fail Fast)
  # --------------------------------------------------------------------------------
  lint:
    name: üßπ Lint & Validate
    needs: filter
    if: needs.filter.outputs.addons != '[]' && needs.filter.outputs.addons != ''
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
      issues: write
    strategy:
      fail-fast: false
      matrix:
        addon: ${{ fromJSON(needs.filter.outputs.addons) }}
    steps:
      - name: ‚§µÔ∏è Check out code
        uses: actions/checkout@v4

      # 1. ShellCheck
      - name: üêö ShellCheck
        uses: ludeeus/action-shellcheck@00cae500b08a931fb5698e11e79bfbd38e612a38 # 2.0.0
        with:
          scandir: "./${{ matrix.addon }}"
        env:
          SHELLCHECK_OPTS: -s bash -e SC2086

      # 2. Hadolint
      - name: üê≥ Hadolint
        uses: brpaz/hadolint-action@v1.5.0
        with:
          dockerfile: "./${{ matrix.addon }}/Dockerfile"

      # 3. Common Linters (Markdown/YAML/JSON/Prettier)
      # ADVISORY CHECKS: These use continue-on-error: true intentionally.
      # Rationale: Formatting issues are auto-fixed by orchestrator-autofix.yaml,
      # so we don't block PRs for style violations. Failures still appear in logs.
      - name: üìù MarkdownLint
        continue-on-error: true # Advisory - auto-fixed by orchestrator-autofix
        uses: actionshub/markdownlint@v3.1.4
        with:
          args: "${{ matrix.addon }}/*.md"

      - name: üìÑ YAMLLint
        continue-on-error: true # Advisory - formatting issues are non-blocking
        uses: frenck/action-yamllint@v1.5
        with:
          args: "./${{ matrix.addon }}/*.yaml"

      - name: üíÖ Prettier
        continue-on-error: true # Advisory - auto-fixed by orchestrator-autofix
        run: |
          npm install -g prettier
          prettier --check "${{ matrix.addon }}/**/*.{json,js,md,yaml}" --ignore-path .prettierignore

      # 4. Add-on Linter (Frenck's) - Validates config.yaml/json
      - name: üïµÔ∏è Add-on Linter
        uses: frenck/action-addon-linter@v2
        with:
          path: "./${{ matrix.addon }}"
        continue-on-error: ${{ matrix.addon == 'netboot-xyz' }}

      # 5. Platinum Compliance (S6, Healthcheck, OCI, Translations, Images)
      - name: üì¶ Install Compliance Deps
        run: pip install pyyaml

      - name: üèÜ Platinum Compliance Check
        id: compliance
        continue-on-error: true
        run: |
          set +e
          # Add addon name as header for report aggregation
          echo "ADDON: ${{ matrix.addon }}" > compliance_report.txt
          python3 .scripts/check_compliance.py "./${{ matrix.addon }}" >> compliance_report.txt 2>&1
          exit_code=$?
          set -e

          echo "::group::Compliance Report"
          cat compliance_report.txt
          echo "::endgroup::"

          if [ "$exit_code" -ne 0 ]; then
            echo "status=failure" >> "$GITHUB_OUTPUT"
          else
            echo "status=success" >> "$GITHUB_OUTPUT"
          fi

      - name: üì§ Upload Compliance Report
        if: steps.compliance.outputs.status == 'failure'
        uses: actions/upload-artifact@v4
        with:
          name: compliance-${{ github.run_id }}-${{ strategy.job-index }}
          path: compliance_report.txt
          retention-days: 1

      - name: üõë Fail if Compliance Error
        if: steps.compliance.outputs.status == 'failure'
        run: |
          echo "::error::Compliance checks failed! See 'Platinum Compliance Check' step for details."
          cat compliance_report.txt
          exit 1

      # 6. Security Scan (Trivy)
      # Scanning the directory for vulnerabilities (fs mode)
      # Note: Scanning the built image is better, but this scans deps/conf before build.
      - name: üõ°Ô∏è Trivy Security Scan
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: "fs"
          scan-ref: "./${{ matrix.addon }}"
          ignore-unfixed: true
          severity: "CRITICAL,HIGH"

  # --------------------------------------------------------------------------------
  # BUILD: Test Build (No Push)
  # --------------------------------------------------------------------------------
  build:
    name: üèóÔ∏è Test Build (${{ matrix.addon }})
    needs: [filter, lint]
    # Skip build if only docs/workflows changed (no Dockerfile, config, scripts)
    if: |
      always() &&
      needs.filter.outputs.addons != '[]' &&
      needs.filter.outputs.addons != '' &&
      needs.filter.outputs.needs_build == 'true'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      # Only matrix on addons, build all arches sequentially on same runner
      matrix:
        addon: ${{ fromJSON(needs.filter.outputs.addons) }}
    steps:
      - name: ‚§µÔ∏è Check out code
        uses: actions/checkout@v4

      - name: üê≥ Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: üíæ Cache Docker layers
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ matrix.addon }}-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-${{ matrix.addon }}-
            ${{ runner.os }}-buildx-

      - name: ‚ÑπÔ∏è Get Add-on Info
        id: info
        uses: home-assistant/actions/helpers/info@master
        with:
          path: "./${{ matrix.addon }}"

      - name: üèóÔ∏è Build All Architectures
        run: |
          ARCHS="${{ join(fromJSON(steps.info.outputs.architectures), ' ') }}"
          IMAGE=$(echo "${{ steps.info.outputs.image }}" | cut -d'/' -f3)

          echo "Building ${{ matrix.addon }} for architectures: $ARCHS"

          for arch in $ARCHS; do
            # Skip 32-bit architectures (deprecated)
            if [[ "$arch" == "armhf" || "$arch" == "armv7" || "$arch" == "i386" ]]; then
              echo "‚è≠Ô∏è Skipping deprecated architecture: $arch"
              continue
            fi

              echo "üî® Building for $arch..."
              docker run --rm --privileged \
                -v /var/run/docker.sock:/var/run/docker.sock \
                -v "$(pwd)":/data \
                -v /tmp/.buildx-cache:/cache \
                ghcr.io/home-assistant/amd64-builder:2025.11.0 \
                --test \
                --"$arch" \
                --target "/data/${{ matrix.addon }}" \
                --image "$IMAGE" \
                --docker-hub "ghcr.io/${{ github.repository_owner }}" \
                --addon \
                --cache-from type=local,src=/cache \
                --cache-to type=local,dest=/cache,mode=max || exit 1
          done

          echo "‚úÖ All architectures built successfully"


  # --------------------------------------------------------------------------------
  # TEST: Runtime Verification (Docker Run)
  # --------------------------------------------------------------------------------
  runtime_test:
    name: üèÉ Runtime Test (${{ matrix.addon }})
    needs: [filter, lint, build]
    # Only run if build is required (skip for docs-only)
    if: |
      always() &&
      needs.filter.outputs.addons != '[]' &&
      needs.filter.outputs.addons != '' &&
      needs.filter.outputs.needs_build == 'true'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        addon: ${{ fromJSON(needs.filter.outputs.addons) }}
    steps:
      - name: ‚§µÔ∏è Check out code
        uses: actions/checkout@v4

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: üì¶ Install Python Dependencies
        run: pip install pyyaml

      - name: üê≥ Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: üíæ Cache Docker layers
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ matrix.addon }}-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-${{ matrix.addon }}-
            ${{ runner.os }}-buildx-

      - name: üèÉ Run Verification Script (DockerBuild + DockerRun)
        run: |
          pwsh -File ./.scripts/verify_addons.ps1 -Addon "${{ matrix.addon }}" -Tests DockerBuild,DockerRun

  report:
    name: üìä CI & Compliance Report
    needs: [filter, lint, build, runtime_test]
    if: failure() && github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
      issues: write
      actions: read
    steps:
      - name: üì• Download Compliance Artifacts
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: compliance-*
          merge-multiple: false
          path: reports

      - name: üìù Post Platinum Compliance Report
        uses: actions/github-script@v7
        continue-on-error: true
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            if (!fs.existsSync('reports')) {
                console.log("No compliance reports found.");
                return;
            }

            const dirs = fs.readdirSync('reports').filter(f => fs.statSync(path.join('reports', f)).isDirectory());

            // Construct workflow run URL
            const workflowRunUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;

            let summary = "## üõ°Ô∏è Platinum Compliance Issues\n\n";
            summary += `> ‚ö†Ô∏è **Note**: This automated summary may contain errors. Always verify by checking the [live workflow logs](${workflowRunUrl}).\n\n`;
            summary += "The following add-ons failed compliance checks:\n\n";
            let hasContent = false;
            let totalIssues = 0;
            let missingHealthchecks = 0;
            let missingLogos = 0;
            let addonsWithHealthcheckIssue = [];
            let addonsWithLogoIssue = [];

            for (const dir of dirs) {
                const reportPath = path.join('reports', dir, 'compliance_report.txt');
                if (fs.existsSync(reportPath)) {
                   const content = fs.readFileSync(reportPath, 'utf8');
                   // Extract addon name from "ADDON: xyz" header line
                   const addonMatch = content.match(/^ADDON: (.+)$/m);
                   const addonName = addonMatch ? addonMatch[1] : dir.replace('compliance-', '');
                   // Remove the ADDON line from display content
                   const displayContent = content.replace(/^ADDON: .+\n/, '');

                   if (content.includes("HEALTHCHECK")) {
                       missingHealthchecks++;
                       addonsWithHealthcheckIssue.push(addonName);
                   }
                   if (content.includes("logo.png")) {
                       missingLogos++;
                       addonsWithLogoIssue.push(addonName);
                   }
                   totalIssues++;

                   summary += `<details>\n<summary><strong>${addonName}</strong>: ‚ùå Issues Found</summary>\n\n\`\`\`\n${displayContent}\n\`\`\`\n</details>\n\n`;
                   hasContent = true;
                }
            }

            // AI-optimized Platinum Compliance Summary
            summary += `<\u0064etails>\n<summary>ü§ñ <strong>AI Fix Instructions</strong></summary>\n\n`;
            summary += `> **Instructions for AI**: Fix all Platinum compliance issues below.\n\n`;

            summary += "```yaml\n";
            summary += "# Platinum Compliance Issues for AI Processing\n";
            summary += `total_addons_with_issues: ${totalIssues}\n\n`;

            if (missingHealthchecks > 0) {
                summary += "healthcheck_issues:\n";
                summary += "  count: " + missingHealthchecks + "\n";
                summary += "  addons:\n";
                for (const addon of addonsWithHealthcheckIssue) {
                    summary += `    - addon: "${addon}"\n`;
                    summary += `      file: "${addon}/Dockerfile"\n`;
                    summary += `      fix: "Add HEALTHCHECK instruction before CMD/ENTRYPOINT"\n`;
                    summary += `      example: 'HEALTHCHECK --interval=30s --timeout=10s CMD curl -f http://127.0.0.1:PORT/health || exit 1'\n`;
                }
            }

            if (missingLogos > 0) {
                summary += "\nlogo_issues:\n";
                summary += "  count: " + missingLogos + "\n";
                summary += "  addons:\n";
                for (const addon of addonsWithLogoIssue) {
                    summary += `    - addon: "${addon}"\n`;
                    summary += `      missing_file: "${addon}/logo.png"\n`;
                    summary += `      requirements: "500x500px PNG with transparent background"\n`;
                    summary += `      action: "Generate or provide logo.png image"\n`;
                }
            }

            summary += "\n# Platinum Standards Checklist:\n";
            summary += "required_files:\n";
            summary += "  - logo.png (500x500px)\n";
            summary += "  - icon.png (128x128px)\n";
            summary += "  - translations/en.yaml\n";
            summary += "  - DOCS.md or README.md\n";
            summary += "dockerfile_requirements:\n";
            summary += "  - HEALTHCHECK instruction\n";
            summary += "  - OCI labels (org.opencontainers.image.*)\n";
            summary += "  - S6 Overlay integration\n";
            summary += "  - Official base image (ghcr.io/hassio-addons/base:19.0.0)\n";
            summary += "```\n";
            summary += "\n</details>\n\n";

            summary += "üíé **Platinum Standards:** Translations (EN/DE) ‚Ä¢ Images (Icon/Logo) ‚Ä¢ Official Base Image ‚Ä¢ S6 Overlay & Healthchecks";

            if (hasContent) {
                // Find existing comments by this bot with signature
                const { data: comments } = await github.rest.issues.listComments({
                   owner: context.repo.owner,
                   repo: context.repo.repo,
                   issue_number: context.issue.number,
                });

                const signature = "## üõ°Ô∏è Platinum Compliance Issues";
                const previousComments = comments.filter(c => c.user.type === 'Bot' && c.body.includes(signature));

                for (const comment of previousComments) {
                    try {
                        await github.graphql(`
                            mutation($subjectId: ID!) {
                                minimizeComment(input: {subjectId: $subjectId, classifier: OUTDATED}) {
                                    minimizedComment {
                                        isMinimized
                                    }
                                }
                            }
                        `, { subjectId: comment.node_id });
                    } catch (error) {
                        console.error(`Failed to minimize comment ${comment.id}:`, error);
                    }
                }

                await github.rest.issues.createComment({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: context.issue.number,
                    body: summary
                });

                // Add ci/platinum-issues label (if only platinum issues, not general failures)
                const { data: currentLabels } = await github.rest.issues.listLabelsOnIssue({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: context.issue.number,
                });

                // Only add platinum-issues if ci/failed is not already set
                const hasFailedLabel = currentLabels.some(l => l.name === 'ci/failed');
                if (!hasFailedLabel) {
                    const ciLabels = ['ci/passed', 'ci/failed', 'ci/platinum-issues'];
                    // Blocklist known invalid labels to prevent flapping
                    const blocklist = ['addon/docker', 'addon/config', 'addon/scripts', 'addon/docs', 'addon/images', 'addon/assets', 'addon/src', 'addon/lib', 'addon/bin', 'addon/test', 'addon/tests'];

                    const filteredLabels = currentLabels.map(l => l.name).filter(n => !ciLabels.includes(n) && !blocklist.includes(n));
                    filteredLabels.push('ci/platinum-issues');

                    await github.rest.issues.setLabels({
                        owner: context.repo.owner,
                        repo: context.repo.repo,
                        issue_number: context.issue.number,
                        labels: filteredLabels
                    });
                }
            }

      - name: üìù Post General CI Failure Report
        uses: actions/github-script@v7
        with:
          script: |
            // Paginate to get ALL jobs (default limit is 30)
            const allJobs = [];
            let page = 1;
            while (true) {
              const { data } = await github.rest.actions.listJobsForWorkflowRun({
                owner: context.repo.owner,
                repo: context.repo.repo,
                run_id: context.runId,
                per_page: 100,
                page: page,
              });
              allJobs.push(...data.jobs);
              if (data.jobs.length < 100) break;
              page++;
            }

            console.log(`Found ${allJobs.length} total jobs in workflow run`);

            // Get jobs that failed directly
            const failedJobs = allJobs.filter(j => j.conclusion === 'failure');

            // ALSO get jobs that succeeded but have failed steps (continue-on-error)
            const jobsWithHiddenFailures = allJobs.filter(j =>
                j.conclusion === 'success' &&
                j.steps &&
                j.steps.some(s => s.conclusion === 'failure')
            );

            // Combine both for reporting
            const allProblematicJobs = [...failedJobs, ...jobsWithHiddenFailures];
            console.log(`Found ${allProblematicJobs.length} problematic jobs`);
            if (allProblematicJobs.length === 0) return;

            // Filter out Compliance-only failures (handled by Platinum Report)
            const nonComplianceJobs = allProblematicJobs.filter(job => {
                const failedStep = job.steps.find(s => s.conclusion === 'failure');
                const stepName = failedStep ? failedStep.name : "";
                return !stepName.includes("Compliance");
            });

            // If all failures are Compliance-related, skip this report (Platinum Report handles it)
            if (nonComplianceJobs.length === 0) {
                console.log("All failures are Compliance-related. Skipping General CI Report.");
                return;
            }

            // Construct workflow run URL
            const workflowRunUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;

            let report = "## ‚ùå General CI Failure Report\n\n";
            report += `> ‚ö†Ô∏è **Note**: This automated summary may contain errors. Always verify by checking the [live workflow logs](${workflowRunUrl}).\n\n`;
            report += `Found **${nonComplianceJobs.length}** failed jobs:\n\n`;

            // Failed Jobs List (excluding Compliance) - with clickable links
            report += "| Job | Step | Link |\n|---|---|---|\n";
            let affectedAddons = new Set();
            let specificTests = new Set();
            let failureTypes = new Set();

            for (const job of nonComplianceJobs) {
                // Regex to capture "addon" from: "Job Name (addon)" or "Job Name (addon - arch)"
                const match = job.name.match(/\((.*?)(?: -.*)?\)/);
                if (match) affectedAddons.add(match[1]);

                const failedStep = job.steps.find(s => s.conclusion === 'failure');
                const stepName = failedStep ? failedStep.name : "Unknown Step";

                // Make job name clickable - link to job logs
                const jobLink = `[${job.name}](${job.html_url})`;
                report += `| ${jobLink} | ${stepName} | [View Logs](${job.html_url}) |\n`;

                // Categorize Failure (excluding Compliance)
                if (stepName.includes("Lint") || stepName.includes("Check") || stepName.includes("Prettier")) failureTypes.add("Linting/Static Analysis");
                if (stepName.includes("Build") || job.name.includes("Build")) failureTypes.add("Docker Build");
                if (stepName.includes("Trivy")) failureTypes.add("Security Scan");
                if (stepName.includes("ShellCheck")) failureTypes.add("ShellCheck");
                if (stepName.includes("Hadolint")) failureTypes.add("Hadolint");

                // Map failed step/job to verification script test name
                if (stepName.includes("ShellCheck")) specificTests.add("ShellCheck");
                else if (stepName.includes("Hadolint")) specificTests.add("Hadolint");
                else if (stepName.includes("MarkdownLint")) specificTests.add("MarkdownLint");
                else if (stepName.includes("YAMLLint")) specificTests.add("YamlLint");
                else if (stepName.includes("Prettier")) specificTests.add("Prettier");
                else if (stepName.includes("Add-on Linter")) specificTests.add("AddonLinter");
                else if (stepName.includes("Trivy")) specificTests.add("Trivy");
                else if (job.name.includes("Build")) specificTests.add("DockerBuild");
            }
            report += "\n";

            // Build comprehensive AI-optimized summary
            report += `<\u0064etails>\n<summary>ü§ñ <strong>AI Fix Instructions</strong></summary>\n\n`;
            report += `> **Instructions for AI**: Fix all issues below. Run local verification after each fix.\n\n`;

            // Group jobs by failure type for better AI processing
            const lintFailures = [];
            const buildFailures = [];
            const securityFailures = [];
            const otherFailures = [];

            for (const job of nonComplianceJobs) {
                const failedStep = job.steps.find(s => s.conclusion === 'failure');
                const stepName = failedStep ? failedStep.name : "Unknown";
                const addonMatch = job.name.match(/\((.*?)(?: -.*)?\)/);
                const addon = addonMatch ? addonMatch[1] : "unknown";

                const entry = { addon, stepName, jobName: job.name, url: job.html_url };

                if (stepName.includes("ShellCheck") || stepName.includes("Hadolint") ||
                    stepName.includes("Lint") || stepName.includes("Prettier") ||
                    stepName.includes("YAML") || stepName.includes("Markdown")) {
                    lintFailures.push(entry);
                } else if (stepName.includes("Build") || job.name.includes("Build")) {
                    buildFailures.push(entry);
                } else if (stepName.includes("Trivy") || stepName.includes("Security")) {
                    securityFailures.push(entry);
                } else {
                    otherFailures.push(entry);
                }
            }

            // AI-optimized structured output
            report += "```yaml\n";
            report += "# CI Failure Analysis for AI Processing\n";
            report += `total_failures: ${nonComplianceJobs.length}\n`;
            report += `workflow_run: ${context.runId}\n\n`;

            if (lintFailures.length > 0) {
                report += "lint_failures:\n";
                report += "  # Fix with: .\\.scripts\\verify_addons.ps1 -Addon <name> -Fix -Tests ShellCheck,Hadolint\n";
                for (const f of lintFailures) {
                    report += `  - addon: "${f.addon}"\n`;
                    report += `    step: "${f.stepName}"\n`;
                    report += `    files_to_check:\n`;
                    if (f.stepName.includes("ShellCheck")) {
                        report += `      - "${f.addon}/**/*.sh"\n`;
                        report += `      - "${f.addon}/run.sh"\n`;
                    }
                    if (f.stepName.includes("Hadolint")) {
                        report += `      - "${f.addon}/Dockerfile"\n`;
                    }
                    if (f.stepName.includes("Add-on Linter")) {
                        report += `      - "${f.addon}/config.yaml"\n`;
                        report += `      - "${f.addon}/build.yaml"\n`;
                    }
                }
            }

            if (buildFailures.length > 0) {
                report += "\nbuild_failures:\n";
                report += "  # Docker build errors - check Dockerfile syntax and base images\n";
                report += "  # Common issues: ARG after FROM, missing packages, invalid base image\n";
                for (const f of buildFailures) {
                    report += `  - addon: "${f.addon}"\n`;
                    report += `    files_to_fix:\n`;
                    report += `      - "${f.addon}/Dockerfile"\n`;
                    report += `      - "${f.addon}/build.yaml"  # Check build_from image\n`;
                    report += `    common_fixes:\n`;
                    report += `      - "Ensure ARG BUILD_FROM is first line after comments"\n`;
                    report += `      - "Check base image exists: ghcr.io/hassio-addons/base:19.0.0"\n`;
                    report += `      - "Verify all APK packages exist for Alpine 3.21"\n`;
                }
            }

            if (securityFailures.length > 0) {
                report += "\nsecurity_failures:\n";
                report += "  # Trivy found vulnerabilities - may need package updates\n";
                report += "  # NOTE: Some vulnerabilities require upstream fixes (not auto-fixable)\n";
                for (const f of securityFailures) {
                    report += `  - addon: "${f.addon}"\n`;
                    report += `    action: "Review Trivy output and update vulnerable packages"\n`;
                    report += `    manual_review_required: true\n`;
                }
            }

            if (otherFailures.length > 0) {
                report += "\nother_failures:\n";
                report += "  # These require manual investigation\n";
                for (const f of otherFailures) {
                    report += `  - addon: "${f.addon}"\n`;
                    report += `    step: "${f.stepName}"\n`;
                    report += `    manual_review_required: true\n`;
                }
            }

            report += "\n# Quick fix commands:\n";
            if (affectedAddons.size > 0) {
                const addonsList = Array.from(affectedAddons).join('","');
                report += `powershell: .\\.scripts\\verify_addons.ps1 -Addon "${addonsList}" -Fix\n`;
                report += `bash: pwsh -File ./.scripts/verify_addons.ps1 -Addon "${addonsList}" -Fix\n`;
            }

            report += "\n# Items NOT fixable by local script:\n";
            report += "not_auto_fixable:\n";
            if (buildFailures.length > 0) {
                report += "  - Docker build errors (require manual Dockerfile fixes)\n";
            }
            if (securityFailures.length > 0) {
                report += "  - Security vulnerabilities (require package updates or upstream fixes)\n";
            }
            report += "  - Missing logo.png/icon.png (need to generate or provide images)\n";
            report += "  - Translation files (need manual creation in translations/en.yaml)\n";
            report += "```\n";
            report += "\n</details>\n\n";

            // Pre-calculate the test command
            let testsArg = "";
            if (specificTests.size > 0) {
                testsArg = ` -Tests "${Array.from(specificTests).join('","')}"`;
            }

            let testCommand = "";
            if (affectedAddons.size > 0) {
                const addonsList = Array.from(affectedAddons).join('","');
                testCommand = `.\\.scripts\\verify_addons.ps1 -Addon "${addonsList}" -Fix${testsArg}`;
            } else {
                testCommand = `.\\.scripts\\verify_addons.ps1 -Addon all -Fix${testsArg}`;
            }

            // Local Test Command (expanded section)
            report += `<details>\n<summary>üíª <strong>Local Test Command</strong></summary>\n\n`;
            report += "Run this command locally to reproduce and fix issues:\n\n";
            report += "**PowerShell:**\n";
            report += "```powershell\n";
            report += testCommand + "\n";
            report += "```\n\n";

            const bashCommand = "pwsh -File " + testCommand.replace(/\\/g, '/').replace(/^\.\\/, './');
            report += "**Bash:**\n";
            report += "```bash\n";
            report += bashCommand + "\n";
            report += "```\n";
            report += "\n</details>";

            const signature = "<!-- general-ci-failure-report -->";
            const reportBody = signature + "\n" + report;

            // Find and minimize old failure reports
            const { data: comments } = await github.rest.issues.listComments({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
            });

            // Standardize old signatures too for transition
            const oldSignatures = ["## ‚ùå General CI Failure Report", signature];
            const previousComments = comments.filter(c => c.user.type === 'Bot' && oldSignatures.some(sig => c.body.includes(sig)));

            for (const comment of previousComments) {
                try {
                    await github.graphql(`
                        mutation($subjectId: ID!) {
                            minimizeComment(input: {subjectId: $subjectId, classifier: OUTDATED}) {
                                minimizedComment { isMinimized }
                            }
                        }
                    `, { subjectId: comment.node_id });
                } catch (error) {
                    console.error(`Failed to minimize comment ${comment.id}:`, error);
                }
            }

            // Post General Report
            await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: reportBody
            });

            // Update CI status labels to ci/failed
            const { data: currentLabels } = await github.rest.issues.listLabelsOnIssue({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
            });

            const ciLabels = ['ci/passed', 'ci/failed', 'ci/platinum-issues'];
            const filteredLabels = currentLabels.map(l => l.name).filter(n => !ciLabels.includes(n));
            filteredLabels.push('ci/failed');

            await github.rest.issues.setLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                labels: filteredLabels
            });

  success_report:
    name: ‚úÖ CI Success Summary
    needs: [filter, lint, build]
    # Run when lint passes and build passes OR was skipped (docs-only changes)
    if: |
      always() &&
      github.event_name == 'pull_request' &&
      needs.lint.result == 'success' &&
      (needs.build.result == 'success' || needs.build.result == 'skipped')
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
      issues: write
    steps:
      - name: üìù Post Success Comment
        uses: actions/github-script@v7
        continue-on-error: true
        with:
          script: |
            const { data: comments } = await github.rest.issues.listComments({
               owner: context.repo.owner,
               repo: context.repo.repo,
               issue_number: context.issue.number,
            });

            // Signatures of comments to minimize (cleanup old failures and summaries)
            const signatures = [
                "<!-- ci-start-comment -->",
                "## üõ°Ô∏è Platinum Compliance Issues",
                "<!-- general-ci-failure-report -->",
                "## ‚ùå General CI Failure Report",
                "## ‚úÖ Verification Successful"
            ];

            const commentsToMinimize = comments.filter(c =>
                c.user.type === 'Bot' &&
                signatures.some(sig => c.body.includes(sig))
            );

            for (const comment of commentsToMinimize) {
                try {
                    await github.graphql(`
                        mutation($subjectId: ID!) {
                            minimizeComment(input: {subjectId: $subjectId, classifier: OUTDATED}) {
                                minimizedComment {
                                    isMinimized
                                }
                            }
                        }
                    `, { subjectId: comment.node_id });
                } catch (error) {
                    console.error(`Failed to minimize comment ${comment.id}:`, error);
                }
            }

            // Check if author is maintainer/bot for auto-merge message
            const author = context.payload.pull_request.user.login;
            const isMaintainer = ['FaserF', 'dependabot[bot]', 'renovate[bot]'].includes(author);

            let autoMergeNote = "";
            if (isMaintainer) {
                autoMergeNote = "\n\n‚è±Ô∏è **Auto-merge will be enabled in 1 minute** if branch protection rules are satisfied.\n\n> üõë To cancel: Add the `no-merge` label or run `gh pr merge --disable-auto`";
            }

            // Check if build was skipped (docs-only changes)
            const buildSkipped = '${{ needs.build.result }}' === 'skipped';
            const buildStatus = buildSkipped ? "‚è≠Ô∏è Skipped (docs-only)" : "‚úÖ Successful";

            // Check for unresolved errors from previous runs
            let previousErrorsNote = "";
            try {
                // Get previous workflow runs for this PR
                const { data: runs } = await github.rest.actions.listWorkflowRunsForRepo({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    event: 'pull_request',
                    status: 'completed',
                    per_page: 10,
                });

                // Filter runs for this PR that failed
                const prRuns = runs.workflow_runs.filter(run =>
                    run.pull_requests &&
                    run.pull_requests.some(pr => pr.number === context.issue.number) &&
                    run.id !== parseInt('${{ github.run_id }}')
                );

                const failedRuns = prRuns.filter(run => run.conclusion === 'failure');

                // Check what files were changed in those failed runs vs now
                if (failedRuns.length > 0 && buildSkipped) {
                    // Build was skipped but there were previous failures
                    // This means the previous failures might still exist!
                    previousErrorsNote = "\n\n> ‚ö†Ô∏è **Note**: Build was skipped for this commit, but there were failed runs earlier in this PR. Make sure all previous issues with Dockerfiles/configs are resolved.";
                }
            } catch (e) {
                console.log("Could not check previous runs:", e.message);
            }


            let body = "## ‚úÖ Verification Successful\n\n";
            body += "Thank you for your contribution!\n\n";
            body += "- üõ°Ô∏è **Platinum Standards**: Compliant\n";
            body += "- üü¢ **CI Checks**: Passed\n";
            body += "- üèóÔ∏è **Build**: " + buildStatus + "\n\n";
            body += "This PR meets high quality standards and is ready for review.";
            body += previousErrorsNote;
            body += autoMergeNote;

            // Check if we already posted a success comment to avoid spamming
            const alreadyPosted = comments.find(c => c.user.type === 'Bot' && c.body.includes("## ‚úÖ Verification Successful"));

            if (!alreadyPosted) {
                await github.rest.issues.createComment({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: context.issue.number,
                    body: body
                });
            }

            // Update CI status labels
            const { data: currentLabels } = await github.rest.issues.listLabelsOnIssue({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
            });

            const ciLabels = ['ci/passed', 'ci/failed', 'ci/platinum-issues'];
            const filteredLabels = currentLabels.map(l => l.name).filter(n => !ciLabels.includes(n));
            filteredLabels.push('ci/passed');

            await github.rest.issues.setLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                labels: filteredLabels
            });

            // Minimize the CI start comment
            const startComment = comments.find(c => c.user.type === 'Bot' && c.body.includes("<!-- ci-start-comment -->"));
            if (startComment) {
                try {
                    await github.graphql(`
                        mutation($subjectId: ID!) {
                            minimizeComment(input: {subjectId: $subjectId, classifier: RESOLVED}) {
                                minimizedComment { isMinimized }
                            }
                        }
                    `, { subjectId: startComment.node_id });
                } catch (e) { console.log("Could not minimize start comment"); }
            }
